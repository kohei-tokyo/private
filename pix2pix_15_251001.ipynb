{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-09T10:33:46.090281Z",
     "start_time": "2025-10-09T10:33:42.314812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from tifffile import tifffile\n",
    "import torch\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import ConcatDataset\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb\n",
    "import torch.nn.functional as F\n",
    "import lpips\n",
    "import itertools\n",
    "print(torch.cuda.is_available())"
   ],
   "id": "6b1d8927d4e75261",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Matsusaka\\PycharmProjects\\DigitalStainingGAN2\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Matsusaka\\PycharmProjects\\DigitalStainingGAN2\\.venv\\Lib\\site-packages\\pydantic\\_internal\\_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if __name__ == '__main__':\n",
    "    from dataset256 import DatasetDigitalStaining\n",
    "    seq_list = []\n",
    "    train_idx = [1,2,3]\n",
    "    val_idx = [4]\n",
    "    test_idx = [0]\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "    # main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\HeLa_Su9-mSG_UNetPipeline\"\n",
    "    main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\HeLa_Su9-mSG_original_crop\"\n",
    "    # main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\COS7_KDEL-mSG_UNetPipeline\"\n",
    "    data_folders = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "    img_folders = [os.path.join(main_dir, f) for f in data_folders]\n",
    "    train_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in train_idx]\n",
    "    val_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in val_idx]\n",
    "    test_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in test_idx]\n",
    "    combined_dataset = ConcatDataset(train_datasets)\n",
    "    train_loader = DataLoader(combined_dataset, batch_size=16, shuffle=True, num_workers=8, pin_memory=True, persistent_workers=True)\n",
    "    combined_dataset = ConcatDataset(val_datasets)\n",
    "    val_loader = DataLoader(combined_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
    "    combined_dataset = ConcatDataset(test_datasets)\n",
    "    test_loader = DataLoader(combined_dataset, batch_size=8, shuffle=False)"
   ],
   "id": "628ea149b0893ec8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def tensor_ssim(img1, img2):\n",
    "    return 1.0 - ssim(img1, img2, data_range=1.0, size_average=True)\n",
    "\n",
    "def dice_loss_calc(pred, target, smooth=1):\n",
    "    \"\"\"\n",
    "    Computes the Dice Loss for binary segmentation.\n",
    "    Args:\n",
    "        pred: Tensor of predictions (batch_size, 1, H, W).\n",
    "        target: Tensor of ground truth (batch_size, 1, H, W).\n",
    "        smooth: Smoothing factor to avoid division by zero.\n",
    "    Returns:\n",
    "        Scalar Dice Loss.\n",
    "    \"\"\"\n",
    "    # Apply sigmoid to convert logits to probabilities\n",
    "    # pred = torch.sigmoid(pred)\n",
    "    # Calculate intersection and union\n",
    "    intersection = (pred * target).sum(dim=(2, 3))\n",
    "    union = pred.sum(dim=(2, 3)) + target.sum(dim=(2, 3))\n",
    "    # Compute Dice Coefficient\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    # Return Dice Loss\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "def lpips_calc(img1, img2, loss_fn):\n",
    "    loss = loss_fn(img1, img2)\n",
    "    return loss.mean()\n",
    "\n",
    "\n",
    "class Patch3(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Patch3, self).__init__()\n",
    "        \n",
    "        def block(in_f, out_f, normalize=True):\n",
    "            \"\"\"Conv → (BN) → LeakyReLU\"\"\"\n",
    "            layers = [nn.Conv2d(in_f, out_f, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_f))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(in_channels, 64, normalize=False),  # (N,64,H/2,W/2)\n",
    "            *block(64, 128),                           # (N,128,H/4,W/4)\n",
    "            *block(128, 256),                          # (N,256,H/8,W/8)\n",
    "            # *block(256, 512),                          # (N,512,H/16,W/16)\n",
    "            nn.Conv2d(256, 1, 4, padding=1)            # 出力 (N,1,H/16-1,W/16-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.model(img)  # \"パッチごと\" の真偽スコア\n",
    "    \n",
    "class Patch4(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Patch4, self).__init__()\n",
    "        \n",
    "        def block(in_f, out_f, normalize=True):\n",
    "            \"\"\"Conv → (BN) → LeakyReLU\"\"\"\n",
    "            layers = [nn.Conv2d(in_f, out_f, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_f))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(in_channels, 64, normalize=False),  # (N,64,H/2,W/2)\n",
    "            *block(64, 128),                           # (N,128,H/4,W/4)\n",
    "            *block(128, 256),                          # (N,256,H/8,W/8)\n",
    "            *block(256, 512),                          # (N,512,H/16,W/16)\n",
    "            nn.Conv2d(512, 1, 4, padding=1)            # 出力 (N,1,H/16-1,W/16-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.model(img)  # \"パッチごと\" の真偽スコア\n",
    "\n",
    "class Patch5(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Patch5, self).__init__()\n",
    "        \n",
    "        def block(in_f, out_f, normalize=True):\n",
    "            \"\"\"Conv → (BN) → LeakyReLU\"\"\"\n",
    "            layers = [nn.Conv2d(in_f, out_f, 4, stride=2, padding=1)]\n",
    "            if normalize:\n",
    "                layers.append(nn.BatchNorm2d(out_f))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            *block(in_channels, 64, normalize=False),  # (N,64,H/2,W/2)\n",
    "            *block(64, 128),                           # (N,128,H/4,W/4)\n",
    "            *block(128, 256),                          # (N,256,H/8,W/8)\n",
    "            *block(256, 512),                          # (N,512,H/16,W/16)\n",
    "            *block(512, 1024),                          # (N,1024,H/32,W/32)\n",
    "            nn.Conv2d(1024, 1, 4, padding=1)            # 出力 (N,1,H/32-1,W/32-1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, img):\n",
    "        return self.model(img)  # \"パッチごと\" の真偽スコア\n",
    "\n",
    "class ResnetPatch(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(ResnetPatch, self).__init__()\n",
    "        resnet = timm.create_model(\"resnet18\", in_chans=in_channels, pretrained=False, num_classes=1)\n",
    "        modules = list(resnet.children())[:-3]  # layer3の後まで\n",
    "        self.model = nn.Sequential(\n",
    "            *modules,\n",
    "            nn.Conv2d(256, 1, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "\n",
    "class StainingGAN():\n",
    "    def __init__(\n",
    "            self, \n",
    "            target = \"mito_preprocess\", # \"{mito or ER}_{preprocess or original}\"\n",
    "            in_chans=2, \n",
    "            n_epoch=100, \n",
    "            w_l1=50, \n",
    "            w_ssim=1.0, \n",
    "            w_dice=1.0, \n",
    "            crop_size=256,\n",
    "            stride=128,\n",
    "            learning_rate_g=0.0002, \n",
    "            learning_rate_d=0.0002,\n",
    "            betas=(0.5, 0.999),\n",
    "            images_to_use=\"both\",\n",
    "            target_image=\"mask\",\n",
    "            device = torch.device(f'cuda:{torch.cuda.current_device()}' if torch.cuda.is_available() else 'cpu'),\n",
    "            name=\"Run\", \n",
    "            discriminator=\"Patch\",\n",
    "            patches_per_epoch=200,\n",
    "            val_epoch=1,\n",
    "            batch_size=16,\n",
    "            num_workers=8,\n",
    "            *args, **kwargs\n",
    "    ):\n",
    "        \n",
    "        global main_dir\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        self.in_chans = in_chans\n",
    "        self.n_epoch = n_epoch\n",
    "        self.betas = betas\n",
    "        self.bce_loss = torch.nn.BCEWithLogitsLoss()\n",
    "        self.w_adv = 0.0 if discriminator == \"NoDiscriminator\" else 1.0\n",
    "        self.w_l1 = w_l1\n",
    "        self.w_ssim = w_ssim\n",
    "        self.w_dice = w_dice\n",
    "        self.crop_size = crop_size\n",
    "        self.stride = stride\n",
    "        self.lr_g = learning_rate_g\n",
    "        self.lr_d = learning_rate_d\n",
    "        self.l1_loss = torch.nn.L1Loss().to(device)\n",
    "        self.loss_fn_mse = torch.nn.MSELoss().to(device)\n",
    "        self.loss_fn_ssim = tensor_ssim\n",
    "        self.loss_fn_lpips = lpips.LPIPS(net='alex').to(device)\n",
    "        self.last_batch_with_pred = None\n",
    "        self.name = name\n",
    "        self.images_to_use = images_to_use\n",
    "        self.target_image = target_image\n",
    "        self.patches_per_epoch = patches_per_epoch\n",
    "        self.val_epoch = val_epoch\n",
    "        self.class_num = 2 if target_image == \"both\" else 1\n",
    "        self.hist = {\"train\": [], \"val\": [], \"test\": []}\n",
    "        self.min_val_loss_mse = 100000\n",
    "        self.min_val_loss_ssim = 100000\n",
    "        self.min_val_loss_lpips = 100000\n",
    "        self.min_val_loss_dice_loss = 100000\n",
    "        \n",
    "        self.G = smp.Unet(\n",
    "            encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "            encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "            in_channels=in_chans,           # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "            classes=self.class_num,                      # model output channels (number of classes in your dataset)\n",
    "            ).to(device)\n",
    "        if discriminator == \"Patch3\":\n",
    "            self.D = Patch3(in_channels=in_chans+self.class_num).to(device)\n",
    "        elif discriminator == \"Patch4\":\n",
    "            self.D = Patch4(in_channels=in_chans+self.class_num).to(device)\n",
    "        elif discriminator == \"Patch5\":\n",
    "            self.D = Patch5(in_channels=in_chans+self.class_num).to(device)\n",
    "        elif discriminator == \"ResnetPatch\":\n",
    "            self.D = ResnetPatch(in_channels=in_chans+self.class_num).to(device)\n",
    "        else:\n",
    "            self.D = timm.create_model(\"resnet18\",\n",
    "                                       in_chans=in_chans+self.class_num,\n",
    "                                       pretrained=False,\n",
    "                                       num_classes=1).to(device)\n",
    "        self.optimizer_g = torch.optim.Adam(self.G.parameters(), lr=self.lr_g, betas=self.betas)\n",
    "        self.optimizer_d = torch.optim.Adam(self.D.parameters(), lr=self.lr_d, betas=self.betas)\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            from dataset256 import DatasetDigitalStaining\n",
    "            if target == \"mito_preprocess\":\n",
    "                data_folders = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "                train_idx = [1,2,3]\n",
    "                val_idx = [4]\n",
    "                test_idx = [0]\n",
    "                main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\HeLa_Su9-mSG_UNetPipeline_crop\"\n",
    "            elif target == \"mito_original\":\n",
    "                data_folders = [\"1\", \"2\", \"3\", \"4\", \"5\"]\n",
    "                train_idx = [1,2,3]\n",
    "                val_idx = [4]\n",
    "                test_idx = [0]\n",
    "                main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\HeLa_Su9-mSG_original_crop\"          \n",
    "            elif target == \"ER_preprocess\":\n",
    "                data_folders = [\"1\", \"2\", \"3\"]\n",
    "                train_idx = [0]\n",
    "                val_idx = [1]\n",
    "                test_idx = [2]\n",
    "                main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\COS7_KDEL-mSG_UNetPipeline_crop\"               \n",
    "            elif target == \"ER_original\":\n",
    "                data_folders = [\"1\", \"2\", \"3\"]\n",
    "                train_idx = [0]\n",
    "                val_idx = [1]\n",
    "                test_idx = [2]\n",
    "                main_dir = \"D:\\\\Matsusaka\\\\data_mito\\\\COS7_KDEL-mSG_original_crop\"     \n",
    "                \n",
    "            os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "            img_folders = [os.path.join(main_dir, f) for f in data_folders]\n",
    "            train_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in train_idx]\n",
    "            val_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in val_idx]\n",
    "            test_datasets = [DatasetDigitalStaining(img_folders[i], augmentation=None) for i in test_idx]\n",
    "            combined_dataset = ConcatDataset(train_datasets)\n",
    "            self.train_loader = DataLoader(combined_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=True, persistent_workers=True)\n",
    "            combined_dataset = ConcatDataset(val_datasets)\n",
    "            self.val_loader = DataLoader(combined_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)\n",
    "            combined_dataset = ConcatDataset(test_datasets)\n",
    "            self.test_loader = DataLoader(combined_dataset, batch_size=8, shuffle=False)\n",
    "        \n",
    "        \n",
    "    def _wandb_init(self):\n",
    "        self.run = wandb.init(\n",
    "            # Set the wandb entity where your project will be logged (generally your team name).\n",
    "            entity=\"kohei_tokyo-the-university-of-tokyo\",\n",
    "            # Set the wandb project where this run will be logged.\n",
    "            project=\"Digital_Staining\",\n",
    "            name=self.name,\n",
    "            # Track hyperparameters and run metadata.\n",
    "            config={\n",
    "                \"learning_rate_g\": self.lr_g,\n",
    "                \"learning_rate_d\": self.lr_d,\n",
    "                \"epochs\": self.n_epoch,\n",
    "                \"images_to_use\": self.images_to_use # phase1, phase2, both, 4qu, or all\n",
    "            },\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def train(self):\n",
    "        self._wandb_init()\n",
    "        for self.epoch in range(self.n_epoch):\n",
    "            print(f\"Epoch {self.epoch+1}/{self.n_epoch}\")\n",
    "            self.calc_epoch(\"train\")\n",
    "            if self.epoch % self.val_epoch == 0:\n",
    "                self.calc_epoch(\"val\")\n",
    "                self.show_result(\"val\")\n",
    "        print(f\"min_epoch_mse {self.min_epoch_mse}\")\n",
    "        print(f\"min_epoch_ssim {self.min_epoch_ssim}\")\n",
    "        print(f\"min_epoch_lpips {self.min_epoch_lpips}\")    \n",
    "    \n",
    "    def test(self):\n",
    "        test_list = [\"final\", \"ssim\", \"mse\", \"lpips\"]\n",
    "        for self.test_id in test_list:\n",
    "            print(f\"Test {self.test_id}\")\n",
    "            if self.test_id != \"final\":\n",
    "                \n",
    "                self.G.load_state_dict(torch.load(f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_G_stain_{self.test_id}_{self.name}.pth\"))\n",
    "                self.D.load_state_dict(torch.load(f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_D_stain_{self.test_id}_{self.name}.pth\"))\n",
    "                self.G.to(self.device)\n",
    "                self.D.to(self.device)\n",
    "            self.calc_epoch(\"test\")\n",
    "            self.show_result(\"test\")\n",
    "        wandb.finish()\n",
    "            \n",
    "    \n",
    "    def calc_epoch(self, mode):\n",
    "        if mode == \"train\":\n",
    "            self.G.train()\n",
    "            self.D.train()\n",
    "            loader = itertools.islice(self.train_loader, self.patches_per_epoch)\n",
    "            patches_num = self.patches_per_epoch\n",
    "            grad_ctx = torch.enable_grad()\n",
    "        elif mode == \"val\":\n",
    "            self.G.eval()\n",
    "            self.D.eval()\n",
    "            loader = self.val_loader\n",
    "            patches_num = len(loader)\n",
    "            grad_ctx = torch.no_grad()\n",
    "        elif mode == \"test\":\n",
    "            self.G.eval()\n",
    "            self.D.eval()\n",
    "            loader = self.test_loader\n",
    "            patches_num = len(loader)\n",
    "            grad_ctx = torch.no_grad()\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        total_metrics_dict = None\n",
    "        \n",
    "        with grad_ctx: \n",
    "            for ph1, ph2, real, real_mask in tqdm(loader, total=patches_num):\n",
    "                metrics = self.calc_batch(ph1, ph2, real, real_mask, mode)\n",
    "                if total_metrics_dict is None:                \n",
    "                    total_metrics_dict = {k:0 for k,v in metrics.items()}\n",
    "                for k, v in metrics.items():\n",
    "                    total_metrics_dict[k] += metrics[k].item()\n",
    "                \n",
    "        for k, v in total_metrics_dict.items():\n",
    "            total_metrics_dict[k] /=  patches_num\n",
    "        self.save_results(total_metrics_dict, mode)\n",
    "                \n",
    "                \n",
    "    def calc_batch(self, ph1, ph2, real, real_mask, mode):\n",
    "        if mode == \"train\":\n",
    "            return self.calc_matrix(ph1, ph2, real, real_mask, mode)\n",
    "        else:\n",
    "            metrics_dict = None\n",
    "            _, _, H, W = ph1.shape\n",
    "            len_met = 0\n",
    "            for i in range(0, H-self.crop_size+1, self.stride):\n",
    "                for j in range(0, W-self.crop_size+1, self.stride):\n",
    "                    len_met += 1\n",
    "                    metrics = self.calc_matrix(\n",
    "                        # ph1,\n",
    "                        # ph2,\n",
    "                        # real,\n",
    "                        # real_mask,\n",
    "                        ph1[:, :, i:i+self.crop_size, j:j+self.crop_size],\n",
    "                        ph2[:, :, i:i+self.crop_size, j:j+self.crop_size],\n",
    "                        real[:, :, i:i+self.crop_size, j:j+self.crop_size],\n",
    "                        real_mask[:, i:i+self.crop_size, j:j+self.crop_size],\n",
    "                        mode\n",
    "                    )\n",
    "                    if metrics_dict is None:                \n",
    "                        metrics_dict = {k:0 for k,v in metrics.items()}\n",
    "                    for k, v in metrics.items():\n",
    "                        metrics_dict[k] += metrics[k]\n",
    "                        \n",
    "            for k, v in metrics_dict.items():\n",
    "                metrics_dict[k] /= len_met\n",
    "            return metrics_dict\n",
    "            \n",
    "    \n",
    "    def calc_matrix(self, ph1, ph2, real, real_mask, mode):\n",
    "        x = torch.concat([ph1, ph2], dim=1).to(self.device)\n",
    "        real = real.to(self.device)\n",
    "        # real_mask = real_mask.unsqueeze(1).to(self.device)\n",
    "        # fake, fake_mask = self.G(x).split(1, dim=1)\n",
    "        fake = F.sigmoid(self.G(x))\n",
    "        # real_pair = torch.cat([x, real, real_mask], dim=1)\n",
    "        # fake_pair = torch.cat([x, fake, fake_mask], dim=1)\n",
    "        real_pair = torch.cat([x, real], dim=1)\n",
    "        fake_pair = torch.cat([x, fake], dim=1)\n",
    "        \n",
    "        loss_d, acc_real, acc_fake = self.calc_dis(real_pair, fake_pair, mode)\n",
    "        # adv_loss, l1_loss, loss_g, mse, ssim_loss, dice_loss = self.calc_gen(\n",
    "        #     real_pair, fake_pair, mode, real, real_mask, fake, fake_mask\n",
    "        # )\n",
    "        adv_loss, loss_g, l1_loss, ssim_loss, mse, lpips_loss = self.calc_gen(\n",
    "            real_pair, fake_pair, mode, real, fake\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"adv_loss_g\": adv_loss, \"l1_loss\":l1_loss, \"loss_g\": loss_g, \"loss_d\": loss_d,\n",
    "            \"mse\": mse, \"ssim\": ssim_loss, \"lpips\": lpips_loss, \"acc_real\": acc_real, \"acc_fake\": acc_fake\n",
    "        }   \n",
    "    \n",
    "    \n",
    "    def calc_dis(self, real_pair, fake_pair, mode):\n",
    "        pred_real = self.D(real_pair)\n",
    "        pred_fake = self.D(fake_pair.detach())\n",
    "        target_real = torch.ones_like(pred_real).to(self.device)\n",
    "        target_fake = torch.zeros_like(pred_fake).to(self.device)\n",
    "        \n",
    "        loss_fake = self.bce_loss(pred_fake, target_fake)\n",
    "        loss_real = self.bce_loss(pred_real, target_real)\n",
    "        loss_d = (loss_real + loss_fake) * 0.5\n",
    "        acc_real = pred_real.sigmoid().float().mean()\n",
    "        acc_fake = pred_fake.sigmoid().float().mean()\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.optimizer_d.zero_grad()\n",
    "            loss_d.backward()\n",
    "            self.optimizer_d.step()\n",
    "            \n",
    "        return loss_d, acc_real, acc_fake\n",
    "    \n",
    "    \n",
    "    def calc_gen(self, real_pair, fake_pair, mode, real, fake):\n",
    "        pred_fake = self.D(fake_pair)\n",
    "        target_fake = torch.ones_like(pred_fake).to(self.device)\n",
    "        \n",
    "        adv_loss = self.bce_loss(pred_fake, target_fake)\n",
    "        l1_loss = self.l1_loss(real, fake)\n",
    "        ssim_loss = self.loss_fn_ssim(real, fake)\n",
    "        mse = self.loss_fn_mse(real, fake)\n",
    "        if mode == \"train\":\n",
    "            lpips_loss = torch.tensor(0.0)\n",
    "        else:\n",
    "            lpips_loss = lpips_calc(real, fake, self.loss_fn_lpips)\n",
    "        # dice_loss = dice_loss_calc(fake_mask, real_mask)\n",
    "        # loss_g = adv_loss + self.w_l1 * l1_loss + self.w_ssim * ssim_loss + self.w_dice * dice_loss\n",
    "        loss_g = self.w_adv * adv_loss + self.w_l1 * l1_loss + self.w_ssim * ssim_loss\n",
    "        \n",
    "        if mode == \"train\":\n",
    "            self.optimizer_g.zero_grad()\n",
    "            loss_g.backward()\n",
    "            self.optimizer_g.step()\n",
    "        \n",
    "        return adv_loss, loss_g, l1_loss, ssim_loss, mse, lpips_loss\n",
    "\n",
    "    \n",
    "    def save_results(self, total_metrics_dict, mode):\n",
    "        self.hist[mode].append(total_metrics_dict)\n",
    "        for k, v in total_metrics_dict.items():\n",
    "            print(f\"{mode} {k}: {v}\")        \n",
    "        total_metrics_dict_log = {f\"{mode}_\"+k:v for k,v in total_metrics_dict.items()}\n",
    "        self.run.log(total_metrics_dict_log)\n",
    "        \n",
    "        if mode == \"val\":\n",
    "            mean_mse = total_metrics_dict['mse']\n",
    "            mean_ssim = total_metrics_dict['ssim']\n",
    "            mean_lpips = total_metrics_dict['lpips']\n",
    "            if mean_mse < self.min_val_loss_mse:\n",
    "                print(f\"Loss_mse improved to {mean_mse}, saving model\")\n",
    "                self.min_val_loss_mse = mean_mse\n",
    "                self.min_epoch_mse = self.epoch\n",
    "                torch.save(self.G.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_G_stain_mse_{self.name}.pth\")\n",
    "                torch.save(self.D.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_D_stain_mse_{self.name}.pth\")\n",
    "            if mean_ssim < self.min_val_loss_ssim:\n",
    "                self.min_val_loss_ssim = mean_ssim\n",
    "                self.min_epoch_ssim = self.epoch\n",
    "                print(f\"Loss_ssim improved to {mean_ssim}, saving model\")\n",
    "                torch.save(self.G.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_G_stain_ssim_{self.name}.pth\")\n",
    "                torch.save(self.D.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_D_stain_ssim_{self.name}.pth\")\n",
    "            if mean_lpips < self.min_val_loss_lpips:\n",
    "                self.min_val_loss_lpips = mean_lpips\n",
    "                self.min_epoch_lpips = self.epoch\n",
    "                print(f\"Loss_lpips improved to {mean_lpips}, saving model\")\n",
    "                torch.save(self.G.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_G_stain_lpips_{self.name}.pth\")\n",
    "                torch.save(self.D.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_D_stain_lpips_{self.name}.pth\")\n",
    "                \n",
    "\n",
    "            # mean_dice_loss = total_metrics_dict['dice_loss']\n",
    "            # if mean_dice_loss < self.min_val_loss_dice_loss:\n",
    "            #     print(f\"Loss_dice_loss improved to {mean_dice_loss}, saving model\")\n",
    "            #     self.min_val_loss_dice_loss = mean_dice_loss\n",
    "            #     self.min_epoch_dice_loss = self.epoch\n",
    "            #     torch.save(self.G.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_G_stain_dice_loss_{self.name}.pth\")\n",
    "            #     torch.save(self.D.state_dict(), f\"C:\\\\Users\\\\Matsusaka\\\\PycharmProjects\\\\DigitalStainingGAN\\\\pth\\\\best_model_D_stain_dice_loss_{self.name}.pth\")\n",
    "                \n",
    "    \n",
    "    def show_result(self, mode):\n",
    "        if mode == \"val\":\n",
    "            loader = self.val_loader\n",
    "            n = 1\n",
    "        elif mode == \"test\":\n",
    "            loader = self.test_loader\n",
    "            n = 6\n",
    "        else:\n",
    "            loader = self.train_loader\n",
    "            n = 1\n",
    "\n",
    "        for ph1, ph2, real, real_mask in loader:\n",
    "            _, _, H, W = ph1.shape\n",
    "\n",
    "            x_crop = torch.cat([ph1.to(self.device), ph2.to(self.device)], dim=1)\n",
    "            with torch.no_grad():\n",
    "                pred_crop = self.G(x_crop)  # [1,2,crop_size,crop_size]\n",
    "            output_pred = pred_crop[0][0]\n",
    "            fake = F.sigmoid(output_pred).cpu().detach().numpy()\n",
    "            fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "            axs[0].imshow(real[0].squeeze())\n",
    "            axs[0].axis('off')\n",
    "            axs[0].set_title('target')\n",
    "            axs[1].imshow(fake)\n",
    "            axs[1].axis('off')\n",
    "            axs[1].set_title('prediction')\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            n = n - 1\n",
    "            # if self.epoch % 5 == 0:\n",
    "            wandb.log({f\"{mode}_pred\" : wandb.Image(fake * 255.0)})\n",
    "            if n <= 0:\n",
    "                break\n",
    "\n",
    "    \n",
    "    def all(self):\n",
    "        self.train()\n",
    "        self.test()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# target_list = [\"mito_preprocess\", \"mito_original\", \"ER_preprocess\", \"ER_original\"]\n",
    "target_list = [\"mito_original\", \"ER_preprocess\", \"ER_original\"]\n",
    "test_names = [\"NoDiscriminator\", \"Resnet\", \"ResnetPatch\", \"Patch3\", \"Patch4\", \"Patch5\"]\n",
    "\n",
    "for target in target_list:\n",
    "    for test_name in test_names:\n",
    "        torch.cuda.memory.empty_cache()\n",
    "        gan = StainingGAN(name=f\"{test_name}_{target}_251007\", n_epoch=50, discriminator=test_name, target=target)\n",
    "        gan.all()\n",
    "torch.cuda.memory.empty_cache()"
   ],
   "id": "ef1bef54a80fadef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5a38646719066395",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
